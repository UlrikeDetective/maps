import os
import osmnx as ox
import geopandas as gpd
import pickle
import time

import preprocessing as pp
def clip_all_input():
    """Clip raw input data (roads + green spaces) to Leipzig-Mitte area."""

    print("Starting data clipping process...")

    pp.clip_to_area(
        input_path="../DataCollection/data/leipzig_roads_walks.geojson",
        clip_mask_path="../DataCollection/data/leipzig_mitte_buildings.geojson",
        output_path="data/leipzig_mitte_roads.geojson"
    )

    pp.clip_to_area(
        input_path="../DataCollection/data/leipzig_green.geojson",
        clip_mask_path="../DataCollection/data/leipzig_mitte_buildings.geojson",
        output_path="data/leipzig_mitte_green.geojson"
    )
    print("All input data clipped.\n")


def load_and_prepare_data():
    # --- Load File Paths ---
    buildings_path = "../DataCollection/data/leipzig_mitte_buildings.geojson"
    greens_path = "data/leipzig_mitte_green.geojson"
    road_path = "data/leipzig_mitte_roads.geojson"
    graphml_path = "../DataCollection/data/leipzig_walk.graphml"
    output_path = "data/green_accessibility.geojson"

    # --- Create Temp Dir and Cache Paths ---
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    snapped_buildings_path = os.path.join(temp_dir, "snapped_buildings.geojson")
    green_nodes_path = os.path.join(temp_dir, "green_nodes.pkl")

    # --- Sanity Check ---
    assert os.path.exists(buildings_path), f"‚ùå Missing: {buildings_path}"
    assert os.path.exists(greens_path), f"‚ùå Missing: {greens_path}"
    assert os.path.exists(graphml_path), f"‚ùå Missing: {graphml_path}"
    print("üìÇ All required input files found.")

    # --- Load Graph ---
    print("üì° Loading road network from saved GraphML...")
    G = ox.load_graphml(graphml_path)
    print(f"‚úÖ Loaded graph with {len(G.nodes)} nodes and {len(G.edges)} edges")

    # --- Load and Preprocess GeoDataFrames ---
    print("üè¢ Loading buildings...")
    gdf_buildings = pp.load_and_reproject(buildings_path)
    print(f"‚úÖ Loaded {len(gdf_buildings)} buildings")

    print("üåø Loading green spaces...")
    gdf_greens_raw = pp.load_and_reproject(greens_path)
    print(f"‚úÖ Loaded {len(gdf_greens_raw)} green features")

    print("üßπ Filtering green polygons...")
    gdf_greens, green_union = pp.filter_green_spaces(gdf_greens_raw)
    print(f"‚úÖ Retained {len(gdf_greens)} green polygons")

    return {
        "buildings_path": buildings_path,
        "greens_path": greens_path,
        "road_path": road_path,
        "graphml_path": graphml_path,
        "output_path": output_path,
        "temp_dir": temp_dir,
        "snapped_buildings_path": snapped_buildings_path,
        "green_nodes_path": green_nodes_path,
        "G": G,
        "gdf_buildings": gdf_buildings,
        "gdf_greens": gdf_greens,
        "green_union": green_union,
    }

#  ------------- Generate & Sample Centroids (with optional save) -------------

def generate_and_sample_centroids(gdf_buildings, use_sample=True, sample_size=100, output_path="temp/centroids.geojson"):
    print("üìç Generating building centroids...")
    gdf_points = pp.generate_building_centroids(gdf_buildings)

    if use_sample:
        print(f"‚ö†Ô∏è Using a sample of {sample_size} centroids for testing...")
        gdf_points = gdf_points.sample(sample_size, random_state=42)

    print(f"‚úÖ Generated {len(gdf_points)} centroids")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    gdf_points.to_file(output_path, driver="GeoJSON")
    print(f"üíæ Centroids saved to: {output_path}")

    return gdf_points


#  ------------- Snap Points and Greens to Graph Nodes (cache if available) -------------

def snap_points_and_greens(G, gdf_points, gdf_greens, points_path, greens_path):
    if os.path.exists(points_path) and os.path.exists(greens_path):
        print("‚ôªÔ∏è Using cached snapped points and green nodes...")
        gdf_points = gpd.read_file(points_path)
        with open(greens_path, "rb") as f:
            green_nodes = pickle.load(f)
    else:
        print("üìå Snapping buildings to nearest graph nodes...")
        gdf_points = pp.snap_points_to_graph(G, gdf_points)
        gdf_points.to_file(points_path, driver="GeoJSON")
        print("‚úÖ Snapping complete and cached")

        print("üå± Snapping green spaces to graph nodes...")
        green_nodes = pp.get_green_space_nodes(G, gdf_greens)
        with open(greens_path, "wb") as f:
            pickle.dump(green_nodes, f)
        print(f"‚úÖ Found and cached {len(green_nodes)} green space nodes")

    return gdf_points, green_nodes

#  ------------- Compute Distances and Add Categories -------------
def compute_accessibility(G, gdf_points, green_nodes):
    print("üö∂ Calculating walking distances and times...")
    start_time = time.time()
    gdf_points = pp.compute_shortest_distances(G, gdf_points, green_nodes)
    print(f"‚úÖ Distance + time calculation complete in {round(time.time() - start_time, 2)} seconds")

    print("üé® Assigning color categories based on walk time...")
    gdf_points = pp.add_accessibility_color(gdf_points)
    print("‚úÖ Colors assigned")

    return gdf_points

#  ------------- Export Final GeoJSON -------------
def export_final_geojson(gdf_points, output_path):
    print("üíæ Exporting final GeoJSON...")

    unsupported_types = ["datetime64[ns]", "object"]
    cols_to_drop = gdf_points.select_dtypes(include=unsupported_types).columns

    if len(cols_to_drop) > 0:
        print(f"‚ö†Ô∏è Dropping unsupported fields before saving: {list(cols_to_drop)}")
        gdf_points = gdf_points.drop(columns=cols_to_drop)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    gdf_points.to_file(output_path, driver="GeoJSON")
    print(f"‚úÖ Accessibility analysis saved to: {output_path}")